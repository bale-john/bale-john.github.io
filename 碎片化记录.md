## 图学习系统对比

|     |AliGraph|DGL|MYL|
| --- | --- | --- | --- |
|可扩展性|分布式|单级并行|分布式|
|计算语义|Embedding lookup|Embedding lookup + Message Passing|Embedding lookup + Message Passing|
|Sampling|图存储侧实现|DL框架侧实现|图计算引擎/DL框架侧实现|
|Aggregating(Encoder)|DL框架侧实现|DL框架侧实现|图计算引擎侧实现|
|Updating(Decoder)|DL框架侧实现|DL框架侧实现|图计算引擎侧实现|
|图存储服务|内置优化|外部适配|存储计算统一|
|计算粒度|Mini-Batch|Mini-Batch/Global-Batch|Mini-Batch/Global-batch/Cluster-batch|

## 图神经网络基于TF和分布式图计算框架实现对比
||基于TF|基于分布式图计算框架|
| --- | --- | --- |
|优点|1. 重用TF库和自动微分<br>2. 自然支持Mini-batch|1. 节点中间层不需要重复计算<br>2. 自然解决某些节点邻居爆炸问题<br> 3. 自然支持深层神经网络|
|缺点|1. 很多节点的中间层重复计算<br>2. 热点难以处理，需要sampling<br>3. 难以支持深层神经网络|1. 不支持自动微分，需要手动首先各个算子的前向后向逻辑<br>2. Mini-Batch同样存在重复计算|

在真实工业场景中，算法的理论时间复杂度和实际耗时有时候差异巨大。
一个例子：两个排序数组，长度分别为m,n。寻找他们的公共元素。最优算法的复杂度为O(m+n)
但在真实实现的过程中，存在各种场景，比如m >> n。这种情况下，先利用二分搜索，将m长度"掐头去尾"，得到两个长度差不多的数组，再寻找公共元素会快很多。
当然其本质仍然可以从算法复杂度上体现，因为m经过掐头去尾后，长度≈n。所以复杂度~O(2n)，而n << m。所以性能提升很多。
同理，还可以衍生出一些别的优化，比如，遍历n数组的每一个元素，去m数组中做二分查找，时间复杂度就成了O(nlogm)。这也有可能比O(m+n)更快。所以要根据具体情况具体分析

std::move(T element) 要注意move的参数不能是const。这很好理解，因为move会将一个左值转化为右值，转化为右值的目的就是为了名正言顺地将这个变量中的某些资源直接拿走。
如果一个变量是const，转化为右值，称为了const T&&,仍然无法改动里面的任何东西，那么转变为右值的意义也就不存在了。事实上如果你有一个函数，希望接受一个右值引用的参数：
f(T&& t)。还有接受左值的版本：f(const T&)
如果传入的是const T&&，那么无法匹配上这个右值版本的函数函数。而是匹配上接受const T&的版本
在明确move的语义后，再扩展一步就可以说清楚完美转发了。仍然以这个为例，f(T&& t)这个函数中，此时的t其实是一个具名对象了，如果要把t作为左值继续传给其他函数，直接使用是会出错的。
这里其实是"引用折叠"的原因，但我们也可以简单理解。此时如何让t保持右值引用的身份传递下去呢，就需要使用完美转发了std::forward

float相加的顺序会导致结果不同，而且随着计算推进误差会累积。浮点数的精度问题注定了无法和整型一样达到"一模一样"。所以在浮点数场景，如果做一些结果验证的事情要注意这一天然的不足。

对于multi-hop activeset。其实就是从target点出发，往外扩散一度的点叫1-hop,2度叫2-hop。针对每个hop的所有点，都实现了一个bitset来当做activeset。
做这个设计的原因是：1-hop的点和2-hop的点需要的计算量是不同的，2-hop其作用就是提供1-hop必要的计算。所以抽象一下就是，一个点处于哪个hop决定了它需要进行多大的计算量
所以为了快速索引每个hop有哪些点需要计算，才实现了这个设计。
在forward阶段，是"从外向内"的计算，最后算出所有target点的loss.backward阶段则正相反，从target点开始向外层层传递
显然一个点有可能是a的1-hop点，同时也是b的2-hop点。这种情况下这个点就正常出现在多个activeset中即可，不会产生问题

在图神经网络的的各种训练策略中。global-batch在效果上是有可能更好的，因为他使用了全部的样本点来确定参数更新的方向。
至少在某些情况下是可能更好的，我们论文的几个实验也证明了这一点。而且global-batch也是和图计算系统相契合的。
支持多策略的一个重要原因，其实是为算法开发者提供更广阔的解探索空间，这一点是很重要的

为什么图神经网络模型在传统DL框架中不容易编写呢？
因为图神经网络模型，可以看作是消息传递的过程，每一个节点会发出它自己的消息，也会接受来自其它节点的消息。然后在得到所有信息之后做聚合，计算出节点新的表征。原有的深度学习框架都是进行张量运算，但是图很多时候并不能直接表示成一个完整的张量，需要手动补零，这其实很麻烦，不高效。
